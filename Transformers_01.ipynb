{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83c727e1-e84d-4f57-8287-1df9287a0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import requests\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a97c7882-6ce7-4001-a3ae-d414753a1fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'input.txt' already exists, skipping download\n",
      "The length of text is 1115394\n"
     ]
    }
   ],
   "source": [
    "if not Path('input.txt').is_file():\n",
    "    print('Downloading \\'input.txt\\'...')\n",
    "    with open('input.txt', 'wb') as f:\n",
    "        request = requests.get('https://github.com/karpathy/ng-video-lecture/raw/master/input.txt')\n",
    "        f.write(request.content)\n",
    "else:\n",
    "    print('\\'input.txt\\' already exists, skipping download')\n",
    "\n",
    "with open('input.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(f'The length of text is {len(text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e18d5e2e-dcc2-4c4a-a1b0-61bbeb6bb193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec300e54-4d9e-4e74-8788-9eac93721c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55635bc8-d0ee-4c50-a897-fefe8fe67f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 47]\n",
      "Hi\n"
     ]
    }
   ],
   "source": [
    "# We can use tiktoken tokenizer which was used for gpt2 or sentencepiece which was developed by google but we're keeping it simple for now\n",
    "\n",
    "stoi = {k:v for v,k in enumerate(chars)}\n",
    "itos = {k:v for k,v in enumerate(chars)}\n",
    "encode = lambda word: [stoi[x] for x in word]\n",
    "decode = lambda word: ''.join([itos[x] for x in word])\n",
    "\n",
    "print(encode('Hi'))\n",
    "print(decode(encode('Hi')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d24a0542-eb9a-475a-a67f-caef700444f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.int64)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4128722-b369-41c7-94db-e6bafe576d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: 1003854 | Test split: 111540\n"
     ]
    }
   ],
   "source": [
    "# Train and test split\n",
    "n = int(0.9 * len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]\n",
    "print(f'Train split: {len(train_data)} | Test split: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dac5c5df-89cc-4f56-9356-232dff36fdb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8720fb00-ae23-4101-9e2b-1ff0d9e07d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([18]), the target is 47\n",
      "When the input is tensor([18, 47]), the target is 56\n",
      "When the input is tensor([18, 47, 56]), the target is 57\n",
      "When the input is tensor([18, 47, 56, 57]), the target is 58\n",
      "When the input is tensor([18, 47, 56, 57, 58]), the target is 1\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1]), the target is 15\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15]), the target is 47\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), the target is 58\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'When the input is {context}, the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5760e15b-e8b4-4e01-bbe7-f6ed727829eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[57,  1, 46, 47, 57,  1, 50, 53],\n",
       "         [ 1, 58, 46, 43, 56, 43,  1, 41],\n",
       "         [17, 26, 15, 17, 10,  0, 32, 53],\n",
       "         [57, 58,  6,  1, 61, 47, 58, 46]]),\n",
       " tensor([[ 1, 46, 47, 57,  1, 50, 53, 60],\n",
       "         [58, 46, 43, 56, 43,  1, 41, 39],\n",
       "         [26, 15, 17, 10,  0, 32, 53,  1],\n",
       "         [58,  6,  1, 61, 47, 58, 46,  0]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "batch_size = 4 # How many batches we would have\n",
    "block_size = 8 # The maximum context length for prediction\n",
    "\n",
    "def get_batch(split):\n",
    "    # Generate small batch of data for X and y inputs\n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, [batch_size])\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "get_batch('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35ba95dc-aad0-4c51-bf16-f47ae38aad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([4, 8])\n",
      "Targets: torch.Size([4, 8])\n",
      "When the input is [6], the target is 0\n",
      "When the input is [6, 0], the target is 14\n",
      "When the input is [6, 0, 14], the target is 43\n",
      "When the input is [6, 0, 14, 43], the target is 44\n",
      "When the input is [6, 0, 14, 43, 44], the target is 53\n",
      "When the input is [6, 0, 14, 43, 44, 53], the target is 56\n",
      "When the input is [6, 0, 14, 43, 44, 53, 56], the target is 43\n",
      "When the input is [6, 0, 14, 43, 44, 53, 56, 43], the target is 1\n",
      "When the input is [39], the target is 1\n",
      "When the input is [39, 1], the target is 42\n",
      "When the input is [39, 1, 42], the target is 59\n",
      "When the input is [39, 1, 42, 59], the target is 43\n",
      "When the input is [39, 1, 42, 59, 43], the target is 1\n",
      "When the input is [39, 1, 42, 59, 43, 1], the target is 39\n",
      "When the input is [39, 1, 42, 59, 43, 1, 39], the target is 52\n",
      "When the input is [39, 1, 42, 59, 43, 1, 39, 52], the target is 42\n",
      "When the input is [47], the target is 41\n",
      "When the input is [47, 41], the target is 43\n",
      "When the input is [47, 41, 43], the target is 1\n",
      "When the input is [47, 41, 43, 1], the target is 39\n",
      "When the input is [47, 41, 43, 1, 39], the target is 52\n",
      "When the input is [47, 41, 43, 1, 39, 52], the target is 42\n",
      "When the input is [47, 41, 43, 1, 39, 52, 42], the target is 1\n",
      "When the input is [47, 41, 43, 1, 39, 52, 42, 1], the target is 42\n",
      "When the input is [53], the target is 44\n",
      "When the input is [53, 44], the target is 1\n",
      "When the input is [53, 44, 1], the target is 50\n",
      "When the input is [53, 44, 1, 50], the target is 43\n",
      "When the input is [53, 44, 1, 50, 43], the target is 58\n",
      "When the input is [53, 44, 1, 50, 43, 58], the target is 1\n",
      "When the input is [53, 44, 1, 50, 43, 58, 1], the target is 58\n",
      "When the input is [53, 44, 1, 50, 43, 58, 1, 58], the target is 46\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print(f'Inputs: {xb.shape}')\n",
    "print(f'Targets: {yb.shape}')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        targets = yb[b, t]\n",
    "        print(f'When the input is {context.tolist()}, the target is {targets}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af74389b-4dae-40b1-b41a-44cf1a112b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: torch.Size([32, 65]), Loss: 4.837806701660156\n",
      "\n",
      "uoiaF$z\n",
      "M?\n"
     ]
    }
   ],
   "source": [
    "# Creating baseline model_0\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, x: torch.tensor, targets: torch.tensor = None) -> torch.tensor:\n",
    "        # print(x.shape)\n",
    "        logits = self.token_embedding_table(x)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # print(f'Logits shape before sizing down: {logits.shape}')\n",
    "            # print(f'logits permute {logits.permute(0,2,1).shape}')\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            # print(f'Logits shape after sizing down: {logits.shape}')\n",
    "            # print(f'Targets before view: {targets}')\n",
    "            targets = targets.view(B*T)\n",
    "            # print(f'Targets after view: {targets}')\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            # print(loss)\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)\n",
    "            # print(idx)\n",
    "            # focus only on the last timestep\n",
    "            # print('Logits before focus:\\n', logits)\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # print('Logits after focus:\\n', logits)\n",
    "            # get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # print(probs)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # print(f'\\nidx_next: {probs.argmax(dim=1)}')\n",
    "            # print(f'\\nidx_next: {idx_next}')\n",
    "            # apply sampled index to the running index\n",
    "            idx = torch.cat([idx, idx_next], dim=1) # (B, T+1)\n",
    "        return idx\n",
    "        \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(f'Logits: {logits.shape}, Loss: {loss}')\n",
    "print(decode(m.generate(torch.zeros(size=[1,1], dtype=torch.int64), max_new_tokens=10)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "660052d6-dd7b-47bf-90f0-ba13d3940ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0852e786-af0b-43fa-9b3e-0b322e554120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1000 | Loss: 3.7676\n",
      "Epoch: 2000 | Loss: 3.1697\n",
      "Epoch: 3000 | Loss: 2.7759\n",
      "Epoch: 4000 | Loss: 2.5619\n",
      "Epoch: 5000 | Loss: 2.5612\n",
      "Epoch: 6000 | Loss: 2.6210\n",
      "Epoch: 7000 | Loss: 2.4096\n",
      "Epoch: 8000 | Loss: 2.5250\n",
      "Epoch: 9000 | Loss: 2.4746\n",
      "Epoch: 10000 | Loss: 2.4609\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(10000):\n",
    "    m.train()\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'Epoch: {epoch + 1} | Loss: {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cb9ed5e-0d6a-49d8-b7fe-120ef330735d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0, 35, 21,  1, 51, 53, 59,  6,  1, 57, 58,  1, 61, 39,  1, 58, 46, 58,\n",
       "         46, 43,  1, 39, 63,  1, 32, 35, 47, 57,  1, 61,  1, 54, 56, 43, 63,  1,\n",
       "         40, 43,  1, 50, 50, 50, 53, 53, 59, 50, 63,  7, 41, 53, 57, 43, 51, 39,\n",
       "         58, 11,  0, 27, 10,  0, 42,  1, 61, 39, 58,  1, 51, 53, 51, 63,  1, 39,\n",
       "         56,  1, 37, 43, 50, 39, 60, 43, 52, 43, 57, 57,  6,  1, 46, 39, 57, 46,\n",
       "         43,  1, 53, 59, 57,  1, 58, 46, 39, 45, 56]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.generate(torch.zeros(size=[1,1], dtype=torch.int64), max_new_tokens=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bea1ec9-afd0-44d6-a991-46eba33873b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ait; l ICotherer w war ha yevelise 'tWhowe murfor add hiull y wharod ongozDI rthHicirds wavente, m \n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(torch.zeros(size=[1,1], dtype=torch.int64), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12c0fa3e-02a7-49d4-9fc8-0aaa40e5bffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Self attention\n",
    "B, T, C = 4, 8, 32 # Batch, Time, Channels\n",
    "x = torch.randn(size=[B, T, C])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "60d6ae6c-ba76-4166-a46a-243293741218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the average of all tokens along with the previous tokens\n",
    "# METHOD 1\n",
    "xbow = torch.zeros(size=[B,T,C])\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1]\n",
    "        xbow[b, t] = xprev.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8872dee-61a4-4ee7-a8fa-624f782f4f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2248e+00,  9.6289e-01, -1.5785e+00,  6.7160e-01, -6.0152e-02,\n",
       "          6.9784e-02, -1.6635e+00, -7.6506e-01,  1.2306e+00,  4.2521e-01,\n",
       "         -1.6383e-02, -1.0749e-01, -1.3086e+00,  6.5981e-01, -7.0325e-02,\n",
       "          2.7448e-01, -3.4501e-01, -1.1962e-01,  1.1862e+00, -1.2203e+00,\n",
       "          2.9100e-01, -7.9642e-02,  1.3200e+00, -1.5197e+00, -2.9336e-01,\n",
       "          2.1066e+00, -1.0875e-01,  6.0834e-01,  7.8943e-01,  7.8247e-01,\n",
       "         -6.4659e-02, -2.3021e-04],\n",
       "        [ 6.8309e-01,  1.0637e-01,  3.5032e-01,  1.2110e-01,  2.9843e-01,\n",
       "          1.3448e+00,  1.4614e+00,  1.0566e+00,  8.1554e-01, -8.2406e-01,\n",
       "          8.9328e-01, -3.8688e-01, -3.5718e-01, -1.1568e+00, -1.7660e+00,\n",
       "         -2.5380e+00,  9.6943e-02, -7.9121e-01,  3.7120e-01,  1.5118e+00,\n",
       "         -8.9146e-01,  5.2475e-01,  3.5178e-01,  2.4913e-01,  1.1900e+00,\n",
       "          1.4109e+00,  7.9801e-01,  4.9413e-01, -1.8495e-01, -1.0381e+00,\n",
       "         -1.0130e-01, -9.2718e-01],\n",
       "        [ 2.3484e-01,  8.8615e-02, -3.4769e-01,  8.4907e-01,  2.0147e-01,\n",
       "          3.8398e-01,  1.2310e+00,  1.2287e+00,  7.0421e-01, -5.6285e-02,\n",
       "         -1.4897e+00, -1.5195e+00,  3.2581e-01, -1.4584e+00,  1.8989e+00,\n",
       "         -4.0566e-02, -2.9337e-01,  1.3978e+00, -9.1666e-01, -7.7937e-01,\n",
       "         -4.1754e-01,  1.1060e+00,  2.5285e-01, -1.0754e-01,  7.7053e-01,\n",
       "         -1.1304e+00,  9.9646e-01, -1.1810e+00,  9.6260e-01, -1.1049e+00,\n",
       "         -7.9095e-01, -2.1609e-01],\n",
       "        [ 1.9485e-03, -2.0979e-01,  1.2010e+00,  6.7560e-01, -1.8900e+00,\n",
       "          1.9432e-01,  1.6020e+00, -1.0372e+00, -7.4869e-01, -3.8440e-01,\n",
       "          1.4350e-01, -8.1268e-02,  1.1262e+00,  4.0618e-02, -6.4642e-02,\n",
       "          3.4456e+00, -1.1129e+00, -4.3420e-01, -1.5212e-02,  5.4272e-01,\n",
       "          1.2508e-01, -8.7617e-01,  1.2223e+00,  3.2682e-01, -1.0487e-01,\n",
       "          2.4768e+00,  5.7691e-01,  1.4731e-01, -1.3136e+00, -6.0611e-01,\n",
       "          6.4498e-01, -2.4771e-01],\n",
       "        [-1.4078e+00, -8.0111e-02,  5.1941e-01,  1.1709e+00,  2.1780e+00,\n",
       "          1.7792e+00,  2.5832e-01, -2.4341e+00, -3.4975e-01, -1.3381e+00,\n",
       "         -4.3891e-01, -5.8502e-01,  1.8071e+00, -7.3262e-01,  4.0940e-01,\n",
       "         -5.8410e-01,  1.0613e-01, -3.0671e-01,  8.6423e-01, -1.0659e+00,\n",
       "         -1.0130e+00, -9.9392e-01,  2.9083e+00,  1.4483e+00, -5.6145e-01,\n",
       "         -9.4646e-01, -7.4197e-01,  1.5562e-01, -2.5844e-01, -7.5015e-01,\n",
       "          1.2355e+00,  1.0141e+00],\n",
       "        [ 1.0132e+00,  6.3464e-01,  8.7688e-01,  8.1428e-01,  1.9737e-01,\n",
       "         -6.3676e-01, -8.7683e-01, -1.5510e+00, -7.8818e-01,  5.6844e-01,\n",
       "          7.6224e-01,  5.5685e-01,  1.2984e+00,  1.7561e+00,  2.1129e-01,\n",
       "          1.4860e+00,  5.5851e-01,  3.4915e-01,  8.4837e-01,  2.0355e+00,\n",
       "          3.7721e-01,  4.8435e-01, -3.0399e-02,  1.0925e+00, -5.0640e-01,\n",
       "         -8.4417e-01, -2.2144e-01,  2.2746e+00, -7.8324e-01, -2.6778e-01,\n",
       "          1.5685e+00, -2.8351e-01],\n",
       "        [-9.6035e-02,  1.0644e+00,  1.4888e+00,  8.8256e-01, -2.3840e-01,\n",
       "          5.4687e-01, -6.0580e-02, -5.3049e-01, -2.0364e+00,  5.2469e-01,\n",
       "         -6.9703e-01, -8.7932e-02, -2.7431e-01,  1.2923e+00, -1.4459e+00,\n",
       "         -3.1467e-01,  1.1260e-01, -1.4679e+00, -1.7168e+00, -5.5025e-01,\n",
       "          5.3508e-01, -1.3392e+00,  1.2358e+00, -2.0371e+00,  1.4171e+00,\n",
       "          1.6868e-01, -1.1421e+00,  6.0696e-01, -8.3318e-01, -4.7921e-01,\n",
       "          2.9985e-01,  7.2138e-01],\n",
       "        [-6.1845e-01,  5.4566e-01, -7.6913e-01,  7.9336e-02, -7.5847e-01,\n",
       "          9.4199e-01,  4.3399e-01,  1.1234e+00,  5.0576e-01, -1.1371e+00,\n",
       "         -7.5818e-01,  4.2283e-02, -6.9009e-01, -5.6215e-01,  8.2530e-01,\n",
       "          2.2683e+00, -1.7733e+00, -9.9073e-01,  6.3486e-01,  1.0238e+00,\n",
       "          9.5747e-01,  1.9130e-02, -1.0700e+00, -7.5189e-01,  2.4401e+00,\n",
       "         -1.9129e+00,  3.1077e-01, -1.4763e+00, -4.7829e-01, -1.1728e-01,\n",
       "         -6.3051e-01, -1.2655e+00]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "21f1c36b-2f2d-49e2-9b18-788425cd47d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2248e+00,  9.6289e-01, -1.5785e+00,  6.7160e-01, -6.0152e-02,\n",
       "          6.9784e-02, -1.6635e+00, -7.6506e-01,  1.2306e+00,  4.2521e-01,\n",
       "         -1.6383e-02, -1.0749e-01, -1.3086e+00,  6.5981e-01, -7.0325e-02,\n",
       "          2.7448e-01, -3.4501e-01, -1.1962e-01,  1.1862e+00, -1.2203e+00,\n",
       "          2.9100e-01, -7.9642e-02,  1.3200e+00, -1.5197e+00, -2.9336e-01,\n",
       "          2.1066e+00, -1.0875e-01,  6.0834e-01,  7.8943e-01,  7.8247e-01,\n",
       "         -6.4659e-02, -2.3021e-04],\n",
       "        [-2.7085e-01,  5.3463e-01, -6.1411e-01,  3.9635e-01,  1.1914e-01,\n",
       "          7.0728e-01, -1.0103e-01,  1.4578e-01,  1.0231e+00, -1.9942e-01,\n",
       "          4.3845e-01, -2.4719e-01, -8.3287e-01, -2.4850e-01, -9.1816e-01,\n",
       "         -1.1317e+00, -1.2403e-01, -4.5541e-01,  7.7868e-01,  1.4574e-01,\n",
       "         -3.0023e-01,  2.2255e-01,  8.3591e-01, -6.3528e-01,  4.4835e-01,\n",
       "          1.7588e+00,  3.4463e-01,  5.5124e-01,  3.0224e-01, -1.2781e-01,\n",
       "         -8.2981e-02, -4.6371e-01],\n",
       "        [-1.0228e-01,  3.8596e-01, -5.2530e-01,  5.4725e-01,  1.4658e-01,\n",
       "          5.9951e-01,  3.4297e-01,  5.0674e-01,  9.1680e-01, -1.5171e-01,\n",
       "         -2.0428e-01, -6.7128e-01, -4.4664e-01, -6.5181e-01,  2.0862e-02,\n",
       "         -7.6801e-01, -1.8048e-01,  1.6233e-01,  2.1357e-01, -1.6263e-01,\n",
       "         -3.3933e-01,  5.1703e-01,  6.4156e-01, -4.5937e-01,  5.5574e-01,\n",
       "          7.9570e-01,  5.6191e-01, -2.6163e-02,  5.2236e-01, -4.5352e-01,\n",
       "         -3.1897e-01, -3.8117e-01],\n",
       "        [-7.6226e-02,  2.3702e-01, -9.3721e-02,  5.7934e-01, -3.6257e-01,\n",
       "          4.9821e-01,  6.5773e-01,  1.2076e-01,  5.0043e-01, -2.0988e-01,\n",
       "         -1.1733e-01, -5.2378e-01, -5.3441e-02, -4.7870e-01, -5.1391e-04,\n",
       "          2.8540e-01, -4.1359e-01,  1.3197e-02,  1.5637e-01,  1.3707e-02,\n",
       "         -2.2323e-01,  1.6873e-01,  7.8673e-01, -2.6282e-01,  3.9059e-01,\n",
       "          1.2160e+00,  5.6566e-01,  1.7204e-02,  6.3366e-02, -4.9167e-01,\n",
       "         -7.7984e-02, -3.4780e-01],\n",
       "        [-3.4254e-01,  1.7359e-01,  2.8906e-02,  6.9765e-01,  1.4554e-01,\n",
       "          7.5441e-01,  5.7785e-01, -3.9021e-01,  3.3039e-01, -4.3552e-01,\n",
       "         -1.8165e-01, -5.3602e-01,  3.1868e-01, -5.2949e-01,  8.1468e-02,\n",
       "          1.1150e-01, -3.0964e-01, -5.0784e-02,  2.9794e-01, -2.0221e-01,\n",
       "         -3.8118e-01, -6.3802e-02,  1.2110e+00,  7.9410e-02,  2.0018e-01,\n",
       "          7.8349e-01,  3.0413e-01,  4.4888e-02, -9.9458e-04, -5.4336e-01,\n",
       "          1.8471e-01, -7.5419e-02],\n",
       "        [-1.1658e-01,  2.5044e-01,  1.7023e-01,  7.1709e-01,  1.5418e-01,\n",
       "          5.2255e-01,  3.3540e-01, -5.8367e-01,  1.4396e-01, -2.6819e-01,\n",
       "         -2.4333e-02, -3.5388e-01,  4.8196e-01, -1.4855e-01,  1.0311e-01,\n",
       "          3.4059e-01, -1.6495e-01,  1.5871e-02,  3.8968e-01,  1.7074e-01,\n",
       "         -2.5478e-01,  2.7556e-02,  1.0041e+00,  2.4826e-01,  8.2415e-02,\n",
       "          5.1221e-01,  2.1654e-01,  4.1650e-01, -1.3137e-01, -4.9743e-01,\n",
       "          4.1533e-01, -1.1010e-01],\n",
       "        [-1.1365e-01,  3.6672e-01,  3.5860e-01,  7.4073e-01,  9.8097e-02,\n",
       "          5.2602e-01,  2.7883e-01, -5.7607e-01, -1.6751e-01, -1.5492e-01,\n",
       "         -1.2043e-01, -3.1589e-01,  3.7392e-01,  5.7283e-02, -1.1818e-01,\n",
       "          2.4698e-01, -1.2530e-01, -1.9610e-01,  8.8752e-02,  6.7743e-02,\n",
       "         -1.4195e-01, -1.6770e-01,  1.0372e+00, -7.8212e-02,  2.7309e-01,\n",
       "          4.6314e-01,  2.2444e-02,  4.4371e-01, -2.3163e-01, -4.9483e-01,\n",
       "          3.9883e-01,  8.6812e-03],\n",
       "        [-1.7675e-01,  3.8909e-01,  2.1764e-01,  6.5805e-01, -8.9732e-03,\n",
       "          5.7802e-01,  2.9823e-01, -3.6363e-01, -8.3356e-02, -2.7770e-01,\n",
       "         -2.0015e-01, -2.7111e-01,  2.4092e-01, -2.0147e-02, -2.4627e-04,\n",
       "          4.9965e-01, -3.3130e-01, -2.9543e-01,  1.5702e-01,  1.8726e-01,\n",
       "         -4.5185e-03, -1.4434e-01,  7.7382e-01, -1.6242e-01,  5.4396e-01,\n",
       "          1.6614e-01,  5.8484e-02,  2.0372e-01, -2.6246e-01, -4.4764e-01,\n",
       "          2.7017e-01, -1.5059e-01]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f5bff2db-9c9c-49b2-9662-eceb92fe7c22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the average of all tokens along with the previous tokens\n",
    "# METHOD 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim=True)\n",
    "xbow2 = wei @ x # (B, T, T) * (B, T, C) ----> (T, C)... batch multiplier\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4226f0ab-0bd8-4a6a-88fe-f7b1a6785e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2248e+00,  9.6289e-01, -1.5785e+00,  ...,  7.8247e-01,\n",
       "          -6.4659e-02, -2.3021e-04],\n",
       "         [-2.7085e-01,  5.3463e-01, -6.1411e-01,  ..., -1.2781e-01,\n",
       "          -8.2981e-02, -4.6371e-01],\n",
       "         [-1.0228e-01,  3.8596e-01, -5.2530e-01,  ..., -4.5352e-01,\n",
       "          -3.1897e-01, -3.8117e-01],\n",
       "         ...,\n",
       "         [-1.1658e-01,  2.5044e-01,  1.7023e-01,  ..., -4.9743e-01,\n",
       "           4.1533e-01, -1.1010e-01],\n",
       "         [-1.1365e-01,  3.6672e-01,  3.5860e-01,  ..., -4.9483e-01,\n",
       "           3.9883e-01,  8.6812e-03],\n",
       "         [-1.7675e-01,  3.8909e-01,  2.1764e-01,  ..., -4.4764e-01,\n",
       "           2.7017e-01, -1.5059e-01]],\n",
       "\n",
       "        [[-2.9485e-01, -2.7986e-01,  1.0837e+00,  ..., -1.1093e-02,\n",
       "          -9.9528e-01, -2.9935e-01],\n",
       "         [ 2.3609e-01, -6.0854e-01, -6.2338e-01,  ...,  1.0225e+00,\n",
       "          -6.1500e-01, -8.2249e-01],\n",
       "         [-1.4801e-02, -6.3508e-01, -2.5709e-01,  ...,  6.9255e-01,\n",
       "          -5.9266e-01, -7.1289e-01],\n",
       "         ...,\n",
       "         [ 6.2443e-01, -7.8174e-01, -1.4438e-01,  ...,  3.4853e-01,\n",
       "          -6.8598e-02, -6.8869e-01],\n",
       "         [ 3.8433e-01, -6.3559e-01, -9.7643e-02,  ...,  3.1369e-01,\n",
       "          -1.0535e-01, -5.4475e-01],\n",
       "         [ 3.2257e-01, -5.4408e-01, -2.7209e-01,  ...,  3.0198e-01,\n",
       "          -5.1569e-02, -3.1178e-01]],\n",
       "\n",
       "        [[-8.4968e-01, -6.9870e-01, -2.0516e-01,  ...,  4.1337e-01,\n",
       "           6.1524e-03, -5.6728e-01],\n",
       "         [-5.1003e-01, -5.0075e-01, -7.4598e-01,  ...,  1.2345e+00,\n",
       "           3.3321e-01, -8.3756e-01],\n",
       "         [-4.3734e-01, -1.8169e-01, -6.0222e-01,  ...,  5.0339e-01,\n",
       "          -2.8198e-01, -5.6118e-02],\n",
       "         ...,\n",
       "         [-3.7622e-01, -2.2356e-01, -1.0907e-01,  ...,  1.2826e-01,\n",
       "          -6.4078e-01,  2.1430e-01],\n",
       "         [-4.6491e-01, -2.4135e-01, -6.2394e-02,  ...,  3.0472e-01,\n",
       "          -8.9523e-01,  1.7182e-01],\n",
       "         [-3.9386e-01, -1.9660e-01, -5.7747e-02,  ...,  3.5391e-01,\n",
       "          -7.7682e-01,  1.8637e-01]],\n",
       "\n",
       "        [[ 5.9505e-02,  1.7286e+00,  2.9208e-01,  ..., -2.3571e+00,\n",
       "          -8.3512e-01, -2.2620e+00],\n",
       "         [-6.1856e-01,  1.0277e+00,  4.4927e-01,  ..., -1.6617e+00,\n",
       "          -1.1291e+00, -1.5233e+00],\n",
       "         [-2.0880e-01,  7.5658e-01,  2.4128e-01,  ..., -7.1679e-01,\n",
       "          -5.2409e-01, -7.2803e-01],\n",
       "         ...,\n",
       "         [-2.2025e-01,  1.6931e-01,  5.0434e-01,  ..., -1.8680e-01,\n",
       "          -1.6989e-01, -4.3293e-01],\n",
       "         [-8.3768e-02,  1.0665e-01,  4.9670e-01,  ..., -1.0063e-01,\n",
       "          -4.9230e-02, -3.3894e-01],\n",
       "         [-1.9275e-01, -3.9274e-03,  5.2130e-01,  ..., -9.2226e-02,\n",
       "          -1.4653e-01, -3.4063e-01]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating the average of all tokens along with the previous tokens\n",
    "# METHOD 3\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = wei.softmax(dim=-1)\n",
    "xbow3 = wei @ x\n",
    "xbow3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b71a7a0-0e1c-4cd4-b252-61e5de598793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = \n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "b = \n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "c = \n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "a = torch.tril(torch.ones(size=[3,3]))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, size=[3,2]).float()\n",
    "c = a @ b\n",
    "print(f'a = \\n{a}')\n",
    "print(f'b = \\n{b}')\n",
    "print(f'c = \\n{c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "af9ef1ad-1d05-4229-8f3c-4a7f604e15ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X before pos embed:\n",
      " tensor([[-1.2248e+00,  9.6289e-01, -1.5785e+00,  6.7160e-01, -6.0152e-02,\n",
      "          6.9784e-02, -1.6635e+00, -7.6506e-01,  1.2306e+00,  4.2521e-01,\n",
      "         -1.6383e-02, -1.0749e-01, -1.3086e+00,  6.5981e-01, -7.0325e-02,\n",
      "          2.7448e-01, -3.4501e-01, -1.1962e-01,  1.1862e+00, -1.2203e+00,\n",
      "          2.9100e-01, -7.9642e-02,  1.3200e+00, -1.5197e+00, -2.9336e-01,\n",
      "          2.1066e+00, -1.0875e-01,  6.0834e-01,  7.8943e-01,  7.8247e-01,\n",
      "         -6.4659e-02, -2.3021e-04],\n",
      "        [ 6.8309e-01,  1.0637e-01,  3.5032e-01,  1.2110e-01,  2.9843e-01,\n",
      "          1.3448e+00,  1.4614e+00,  1.0566e+00,  8.1554e-01, -8.2406e-01,\n",
      "          8.9328e-01, -3.8688e-01, -3.5718e-01, -1.1568e+00, -1.7660e+00,\n",
      "         -2.5380e+00,  9.6943e-02, -7.9121e-01,  3.7120e-01,  1.5118e+00,\n",
      "         -8.9146e-01,  5.2475e-01,  3.5178e-01,  2.4913e-01,  1.1900e+00,\n",
      "          1.4109e+00,  7.9801e-01,  4.9413e-01, -1.8495e-01, -1.0381e+00,\n",
      "         -1.0130e-01, -9.2718e-01],\n",
      "        [ 2.3484e-01,  8.8615e-02, -3.4769e-01,  8.4907e-01,  2.0147e-01,\n",
      "          3.8398e-01,  1.2310e+00,  1.2287e+00,  7.0421e-01, -5.6285e-02,\n",
      "         -1.4897e+00, -1.5195e+00,  3.2581e-01, -1.4584e+00,  1.8989e+00,\n",
      "         -4.0566e-02, -2.9337e-01,  1.3978e+00, -9.1666e-01, -7.7937e-01,\n",
      "         -4.1754e-01,  1.1060e+00,  2.5285e-01, -1.0754e-01,  7.7053e-01,\n",
      "         -1.1304e+00,  9.9646e-01, -1.1810e+00,  9.6260e-01, -1.1049e+00,\n",
      "         -7.9095e-01, -2.1609e-01],\n",
      "        [ 1.9485e-03, -2.0979e-01,  1.2010e+00,  6.7560e-01, -1.8900e+00,\n",
      "          1.9432e-01,  1.6020e+00, -1.0372e+00, -7.4869e-01, -3.8440e-01,\n",
      "          1.4350e-01, -8.1268e-02,  1.1262e+00,  4.0618e-02, -6.4642e-02,\n",
      "          3.4456e+00, -1.1129e+00, -4.3420e-01, -1.5212e-02,  5.4272e-01,\n",
      "          1.2508e-01, -8.7617e-01,  1.2223e+00,  3.2682e-01, -1.0487e-01,\n",
      "          2.4768e+00,  5.7691e-01,  1.4731e-01, -1.3136e+00, -6.0611e-01,\n",
      "          6.4498e-01, -2.4771e-01],\n",
      "        [-1.4078e+00, -8.0111e-02,  5.1941e-01,  1.1709e+00,  2.1780e+00,\n",
      "          1.7792e+00,  2.5832e-01, -2.4341e+00, -3.4975e-01, -1.3381e+00,\n",
      "         -4.3891e-01, -5.8502e-01,  1.8071e+00, -7.3262e-01,  4.0940e-01,\n",
      "         -5.8410e-01,  1.0613e-01, -3.0671e-01,  8.6423e-01, -1.0659e+00,\n",
      "         -1.0130e+00, -9.9392e-01,  2.9083e+00,  1.4483e+00, -5.6145e-01,\n",
      "         -9.4646e-01, -7.4197e-01,  1.5562e-01, -2.5844e-01, -7.5015e-01,\n",
      "          1.2355e+00,  1.0141e+00],\n",
      "        [ 1.0132e+00,  6.3464e-01,  8.7688e-01,  8.1428e-01,  1.9737e-01,\n",
      "         -6.3676e-01, -8.7683e-01, -1.5510e+00, -7.8818e-01,  5.6844e-01,\n",
      "          7.6224e-01,  5.5685e-01,  1.2984e+00,  1.7561e+00,  2.1129e-01,\n",
      "          1.4860e+00,  5.5851e-01,  3.4915e-01,  8.4837e-01,  2.0355e+00,\n",
      "          3.7721e-01,  4.8435e-01, -3.0399e-02,  1.0925e+00, -5.0640e-01,\n",
      "         -8.4417e-01, -2.2144e-01,  2.2746e+00, -7.8324e-01, -2.6778e-01,\n",
      "          1.5685e+00, -2.8351e-01],\n",
      "        [-9.6035e-02,  1.0644e+00,  1.4888e+00,  8.8256e-01, -2.3840e-01,\n",
      "          5.4687e-01, -6.0580e-02, -5.3049e-01, -2.0364e+00,  5.2469e-01,\n",
      "         -6.9703e-01, -8.7932e-02, -2.7431e-01,  1.2923e+00, -1.4459e+00,\n",
      "         -3.1467e-01,  1.1260e-01, -1.4679e+00, -1.7168e+00, -5.5025e-01,\n",
      "          5.3508e-01, -1.3392e+00,  1.2358e+00, -2.0371e+00,  1.4171e+00,\n",
      "          1.6868e-01, -1.1421e+00,  6.0696e-01, -8.3318e-01, -4.7921e-01,\n",
      "          2.9985e-01,  7.2138e-01],\n",
      "        [-6.1845e-01,  5.4566e-01, -7.6913e-01,  7.9336e-02, -7.5847e-01,\n",
      "          9.4199e-01,  4.3399e-01,  1.1234e+00,  5.0576e-01, -1.1371e+00,\n",
      "         -7.5818e-01,  4.2283e-02, -6.9009e-01, -5.6215e-01,  8.2530e-01,\n",
      "          2.2683e+00, -1.7733e+00, -9.9073e-01,  6.3486e-01,  1.0238e+00,\n",
      "          9.5747e-01,  1.9130e-02, -1.0700e+00, -7.5189e-01,  2.4401e+00,\n",
      "         -1.9129e+00,  3.1077e-01, -1.4763e+00, -4.7829e-01, -1.1728e-01,\n",
      "         -6.3051e-01, -1.2655e+00]])\n",
      "X after pos embed:\n",
      " tensor([[-2.0226e+00,  1.9890e+00, -4.3199e-01,  6.8035e-01, -3.6361e-01,\n",
      "         -1.0025e+00, -1.7959e+00,  2.6636e-01,  3.5849e-01,  6.1160e-01,\n",
      "          1.7405e+00,  1.1212e+00, -7.1458e-01,  1.3483e+00, -5.8160e-01,\n",
      "          1.0781e+00,  1.2162e+00, -6.6099e-01,  2.0037e-01, -1.9037e+00,\n",
      "         -3.5887e-02, -9.1180e-01,  3.2831e+00, -9.2751e-01, -9.2988e-01,\n",
      "          1.9066e+00, -2.2591e+00,  7.3575e-01,  1.1678e+00,  2.5759e+00,\n",
      "          8.7883e-01, -6.7259e-01],\n",
      "        [ 1.4136e+00,  2.3559e+00,  4.6169e-01, -2.7203e+00, -5.0719e-01,\n",
      "          2.7652e+00,  2.2647e+00,  1.8014e+00, -7.2124e-01, -1.8772e+00,\n",
      "          9.6121e-01, -1.8571e+00, -2.0707e+00, -1.0841e+00, -1.9296e+00,\n",
      "         -4.3484e+00,  2.4022e-01, -6.3048e-01,  1.0934e+00, -2.8879e-01,\n",
      "          5.4262e-01,  5.8764e-02,  9.7290e-01,  2.6710e-01,  7.5784e-01,\n",
      "          1.0632e+00,  1.7717e+00,  1.6705e+00, -3.1058e-01,  1.7527e-01,\n",
      "          8.3410e-01, -1.0052e+00],\n",
      "        [-1.2299e+00, -1.8685e+00, -2.4596e-01,  5.0501e-01,  1.4460e+00,\n",
      "          4.4102e-01,  2.1791e+00,  2.1922e+00,  1.3974e+00,  1.1719e+00,\n",
      "         -6.7747e-01, -2.8704e+00, -2.9736e-01,  7.1947e-01,  3.3587e+00,\n",
      "         -1.0374e+00, -3.8179e-01,  1.0403e+00, -2.6942e+00, -7.4956e-01,\n",
      "         -5.3682e-02,  4.0113e-01,  1.0335e+00,  1.1337e+00, -5.2062e-01,\n",
      "         -4.3325e-01,  1.5553e+00, -7.4110e-01,  1.6368e+00, -1.6813e+00,\n",
      "         -1.6360e+00, -7.8619e-01],\n",
      "        [-3.7263e-01,  2.2029e-01,  5.8817e-01, -4.5675e-01, -1.9901e+00,\n",
      "          1.5893e+00,  3.8411e+00, -1.4835e+00, -1.0524e+00, -1.9602e+00,\n",
      "         -5.4418e-01,  1.2980e-03,  2.2639e+00,  1.8918e+00,  4.6084e-02,\n",
      "          3.4728e+00, -1.4612e+00, -7.7295e-01,  6.3558e-01,  2.7187e+00,\n",
      "          4.4610e-01,  4.5005e-01,  1.6339e+00,  1.4361e+00,  6.7768e-01,\n",
      "          1.1315e+00,  6.9392e-02, -3.0299e-01, -8.4945e-01, -2.6047e+00,\n",
      "         -9.5933e-02,  4.5335e-01],\n",
      "        [-2.8016e+00,  7.6644e-01, -1.1997e+00,  1.7042e+00,  9.8756e-01,\n",
      "          2.1213e+00, -4.1871e-02, -1.4296e+00,  3.4254e-01, -2.8957e-01,\n",
      "         -5.8994e-01, -2.8827e+00,  1.6827e+00, -1.5323e+00,  1.1524e+00,\n",
      "         -1.3927e+00, -4.0120e-01, -1.0002e+00,  1.7523e+00, -2.5985e+00,\n",
      "         -1.5102e+00, -4.0250e-01,  4.0274e+00,  1.6023e+00, -1.8550e+00,\n",
      "         -1.5173e+00,  6.4144e-01,  7.8082e-01, -9.1072e-01, -1.5882e+00,\n",
      "         -2.3741e-02,  1.3283e+00],\n",
      "        [ 1.5322e+00,  1.2056e+00,  2.5409e+00,  3.0055e+00, -7.7949e-01,\n",
      "         -2.4975e+00, -1.1161e+00, -9.8664e-01, -4.4888e-01,  2.0985e+00,\n",
      "          3.4533e+00,  1.2150e+00,  1.0122e-01, -2.0434e-01, -5.4596e-01,\n",
      "          4.8004e-01,  9.7628e-02, -4.2111e-01, -4.6479e-01,  1.9845e+00,\n",
      "          1.8729e+00,  1.3295e+00, -4.5488e-01,  2.4177e+00, -5.5308e-01,\n",
      "         -1.3788e+00,  1.4380e+00,  1.9342e+00, -2.0387e+00, -1.4545e+00,\n",
      "          1.7005e+00,  5.7221e-02],\n",
      "        [-2.7723e+00, -3.5175e-01,  2.8074e+00,  6.7103e-01, -1.2700e+00,\n",
      "          2.2199e+00,  1.6642e+00,  4.0289e-01, -3.4330e+00,  7.0629e-01,\n",
      "         -2.7017e+00, -1.5829e+00,  3.2163e-01,  9.2879e-01, -1.6735e+00,\n",
      "         -9.3892e-01, -6.0671e-01, -1.5389e+00, -2.4552e+00, -1.2554e+00,\n",
      "          9.8930e-01, -1.0775e+00,  2.0009e-02, -2.2930e+00,  2.9296e-01,\n",
      "          1.3965e+00, -1.1129e+00,  2.4779e+00, -1.1447e+00, -2.0615e-01,\n",
      "         -4.9169e-01,  7.0997e-01],\n",
      "        [-7.5121e-01,  2.4129e+00, -6.1844e-02, -9.2914e-02, -7.6944e-01,\n",
      "          3.5603e-01,  2.4624e+00,  1.0083e+00,  6.8306e-01, -2.0577e-01,\n",
      "         -1.9100e+00,  4.6464e-01, -6.0404e-01, -2.0489e+00, -1.8177e-02,\n",
      "          1.2873e+00, -1.4214e+00,  3.5141e-01,  1.6543e+00, -5.4121e-02,\n",
      "          1.7287e+00,  4.8748e-01, -1.7920e+00, -1.4720e+00,  1.0461e+00,\n",
      "          6.5028e-02,  9.6950e-01, -7.2767e-01, -1.2848e+00,  3.2313e-01,\n",
      "          4.9689e-01, -1.0887e+00]], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embed_table = nn.Embedding(T, C)\n",
    "print(f'X before pos embed:\\n {x[0]}')\n",
    "pos_embed = x + embed_table(torch.arange(T))\n",
    "print(f'X after pos embed:\\n {pos_embed[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c63cb14d-e271-4334-8e9a-225313ffc3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement single self attention head, the hyper parameter involved is the head size\n",
    "torch.manual_seed(42)\n",
    "\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "wei = k @ q.transpose(-1, -2) * head_size**-0.5 # Transpose the last two dimensions k(B, T, 16) @ q(B, 16, T)\n",
    "tril = torch.tril(torch.ones(T, T)) # For decoder blocks only\n",
    "wei = wei.masked_fill(tril[:T, :T] == 0, float('-inf')) # For decoder blocks only\n",
    "wei = wei.softmax(dim=-1)\n",
    "out = wei @ v\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "eee66818-6301-495e-813f-4a727540eb75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4497, 0.5503, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2722, 0.2643, 0.4634, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2855, 0.2142, 0.2455, 0.2548, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1407, 0.1532, 0.2461, 0.2000, 0.2600, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1482, 0.1193, 0.1536, 0.1219, 0.2351, 0.2219, 0.0000, 0.0000],\n",
       "        [0.1431, 0.1660, 0.0998, 0.1260, 0.1595, 0.1397, 0.1658, 0.0000],\n",
       "        [0.0974, 0.1426, 0.0655, 0.1600, 0.0771, 0.1042, 0.2682, 0.0849]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c4c01377-7c28-4731-9101-0e45b23d23c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k, q = torch.randn(B, T, head_size), torch.randn(B, T, head_size)\n",
    "wei = k @ q.transpose(-1, -2) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "65b79b4b-dbf8-4823-b361-39cada82315f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9402)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7630674b-a924-409a-bc18-008e3f9370a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9806)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5dc7cc31-e6ae-44cd-a074-151db9d1802e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9635)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce4ea1-b0f5-411a-85c6-ead843ad5eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
